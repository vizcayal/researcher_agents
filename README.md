# Deep Research Agents ğŸ”

An agentic research pipeline that helps you clarify topics, plan research, and automatically gather information from the web to generate comprehensive Markdown reports.

## ğŸš€ Features

- **Topic Clarification**: Iteratively refines broad research questions into specific, actionable topics.
- **Strategic Planning**: Generates structured research plans to cover all necessary aspects of a topic.
- **Agentic Coordination**: Uses `smolagents` and Firecrawl MCP to orchestrate search sub-agents that browse the web and synthesize findings.
- **Robust Model Support**: Specifically optimized for "Reasoning" models (like DeepSeek-R1) and stable tool-calling models (like Qwen-2.5-Coder).
- **Corporate Network Ready**: Includes automated SSL certificate handling via `truststore` to bypass common proxy errors.

## ğŸ› ï¸ Project Structure

```text
researcher-agents/
â”œâ”€â”€ main.py              # CLI Entry point
â”œâ”€â”€ app.py               # Streamlit UI
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ src/                 # Core Agents
    â”œâ”€â”€ clarifier.py     # Topic refinement
    â”œâ”€â”€ planner.py       # Strategic planning
    â”œâ”€â”€ splitter.py      # Task decomposition
    â”œâ”€â”€ coordinator.py   # Agent orchestration
    â””â”€â”€ prompts.py       # LLM Instructions
```

## âš™ï¸ Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/vizcayal/researcher_agents.git
   cd researcher_agents
   ```

2. **Create a virtual environment**:
   ```bash
   python -m venv .venv
   .\.venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Environment Variables**:
   Create a `.env` file in the root directory:
   ```env
   HF_KEY=your_huggingface_token
   FIRECRAWL_KEY=your_firecrawl_api_key
   ```

## ğŸ“– Usage

### Command Line Interface
Run the full automated research pipeline:
```bash
python main.py
```

### Streamlit Web App
Run the interactive UI (currently supports Clarification and Planning):
```bash
streamlit run app.py
```

## ğŸ¤– Recommended Models
The project is configured to work with the Hugging Face Serverless Inference API:
- **Reasoning**: `deepseek-ai/DeepSeek-R1-Distill-Llama-8B`
- **Orchestration**: `Qwen/Qwen2.5-Coder-32B-Instruct`
- **Output**: `meta-llama/Llama-3.3-70B-Instruct`

## ğŸ“„ License
MIT
